{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Object Segmentation on 360 Images — Hands-On Demo\n",
        "\n",
        "In this notebook, we'll use **[PanoSAM](https://github.com/yz3440/panosam)** to detect and segment objects in equirectangular panoramic images using **text prompts**.\n",
        "\n",
        "PanoSAM wraps **[Meta SAM 3](https://ai.meta.com/sam3/)** (Segment Anything Model 3) and handles the full panorama pipeline — perspective splitting, per-view segmentation, coordinate conversion back to spherical, and mask deduplication — so you don't have to do any of that manually.\n",
        "\n",
        "```mermaid\n",
        "graph LR\n",
        "    A[\"Equirectangular<br/>panorama\"] --> B[\"Perspective Views<br/>(auto-generated)\"] --> C[\"SAM 3 (per view)<br/>text prompt\"] --> D[\"Deduplicated Masks<br/>in spherical coords\"]\n",
        "```\n",
        "\n",
        "**Note:** SAM 3 is a large model and requires a HuggingFace token. A GPU is recommended for reasonable speed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Install Dependencies\n",
        "\n",
        "PanoSAM has install extras for different use cases:\n",
        "- `panosam[sam3]` — includes SAM 3 engine dependencies (HuggingFace Transformers)\n",
        "- `panosam[viz]` — visualization utilities\n",
        "- `panosam[full]` — everything"
      ],
      "id": "769f42d2"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "!pip install \"panosam[full]\""
      ],
      "execution_count": null,
      "outputs": [],
      "id": "2e79d6b9"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Load a Panorama\n",
        "\n",
        "Place an equirectangular image at `assets/sample_panorama.jpg`, or the cell below will download one from Google Street View."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "SAMPLE_IMAGE = \"assets/sample_panorama.jpg\"\n",
        "\n",
        "if not os.path.exists(SAMPLE_IMAGE):\n",
        "    print(\"No sample image found. Downloading from Google Street View...\")\n",
        "    from streetlevel import streetview\n",
        "    pano = streetview.find_panorama(42.3625, -71.0862)  # MIT Media Lab area\n",
        "    if pano:\n",
        "        os.makedirs(\"assets\", exist_ok=True)\n",
        "        streetview.download_panorama(pano, SAMPLE_IMAGE, zoom=4)\n",
        "        print(f\"Downloaded panorama {pano.id}\")\n",
        "\n",
        "panorama = Image.open(SAMPLE_IMAGE)\n",
        "print(f\"Panorama size: {panorama.width} x {panorama.height}\")\n",
        "\n",
        "plt.figure(figsize=(16, 8))\n",
        "plt.imshow(panorama)\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Equirectangular Panorama\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "a6933783"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Perspective Splitting (Handled by PanoSAM)\n",
        "\n",
        "SAM 3 expects standard perspective images. PanoSAM handles the equirectangular-to-perspective projection automatically using configurable **perspective presets**:\n",
        "\n",
        "| Preset | FOV | Resolution | Views |\n",
        "|---|---|---|---|\n",
        "| `DEFAULT` | 45° | 2048×2048 | 16 |\n",
        "| `ZOOMED_IN` | 22.5° | 1024×1024 | 32 |\n",
        "| `ZOOMED_OUT` | 60° | 2500×2500 | 12 |\n",
        "| `WIDEANGLE` | 90° | 2500×2500 | 8 |\n",
        "\n",
        "You can also create custom perspectives with `panosam.generate_perspectives()` for fine-grained control over FOV, resolution, overlap, and pitch angles.\n",
        "\n",
        "Let's peek at what the perspective views look like:"
      ],
      "id": "8eee2e59"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import panosam as ps\n",
        "\n",
        "# PanoSAM uses PanoramaImage to handle perspective generation\n",
        "pano_image = ps.PanoramaImage(panorama_id=\"sample\", image=panorama)\n",
        "\n",
        "# Look at the DEFAULT preset perspectives\n",
        "perspectives = ps.DEFAULT_IMAGE_PERSPECTIVES\n",
        "print(f\"DEFAULT preset: {len(perspectives)} perspectives\")\n",
        "for p in perspectives[:4]:\n",
        "    print(f\"  yaw={p.yaw_offset:6.1f}°, pitch={p.pitch_offset:5.1f}°, fov={p.horizontal_fov}°, res={p.width}×{p.height}\")\n",
        "print(f\"  ... and {len(perspectives) - 4} more\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "bf4d4257"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Generate and display a few perspective views from the panorama\n",
        "sample_perspectives = perspectives[:6]  # Show first 6\n",
        "\n",
        "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
        "for idx, p in enumerate(sample_perspectives):\n",
        "    persp_image = pano_image.generate_perspective_image(p)\n",
        "    pil_view = persp_image.get_perspective_image()\n",
        "\n",
        "    ax = axes[idx // 3][idx % 3]\n",
        "    ax.imshow(pil_view)\n",
        "    ax.set_title(f\"Yaw: {p.yaw_offset:.0f}°, Pitch: {p.pitch_offset:.0f}°\")\n",
        "    ax.axis(\"off\")\n",
        "\n",
        "plt.suptitle(\"Perspective Views (auto-generated by PanoSAM)\", fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "10eed7e1"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Run PanoSAM Segmentation\n",
        "\n",
        "PanoSAM handles the entire pipeline in one call:\n",
        "1. Splits the panorama into perspective views (based on the chosen preset)\n",
        "2. Runs SAM 3 on each view with your text prompt\n",
        "3. Converts per-view masks to spherical coordinates\n",
        "4. Deduplicates overlapping detections across views\n",
        "\n",
        "**Prerequisites:**\n",
        "- HuggingFace authentication: `huggingface-cli login` (accept the [SAM 3 license](https://huggingface.co/facebook/sam3))\n",
        "- GPU recommended for reasonable speed"
      ],
      "id": "3c60cf7d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "TEXT_PROMPT = \"car\"  # Try: \"sign\", \"tree\", \"window\", \"person\", \"building\"\n",
        "\n",
        "print(f\"Will segment '{TEXT_PROMPT}' across the full panorama.\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "87ac77d8"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from panosam.engines.sam3 import SAM3Engine\n",
        "\n",
        "try:\n",
        "    # Initialize the SAM3 engine (downloads model on first run)\n",
        "    engine = SAM3Engine()\n",
        "\n",
        "    # Create the PanoSAM client with the WIDEANGLE preset (8 views, fast)\n",
        "    # Use ps.PerspectivePreset.DEFAULT (16 views) for higher coverage\n",
        "    client = ps.PanoSAM(engine=engine, views=ps.PerspectivePreset.WIDEANGLE)\n",
        "\n",
        "    # Segment — this splits, runs SAM3, converts to spherical, and deduplicates\n",
        "    result = client.segment(panorama, prompt=TEXT_PROMPT)\n",
        "\n",
        "    print(f\"Found {len(result.masks)} '{TEXT_PROMPT}' instance(s) across the panorama\\n\")\n",
        "    for i, mask in enumerate(result.masks):\n",
        "        print(f\"  [{i}] score={mask.score:.2f}, \"\n",
        "              f\"center=({mask.center_yaw:.1f}°, {mask.center_pitch:.1f}°), \"\n",
        "              f\"polygons={len(mask.polygons)}\")\n",
        "\n",
        "except ImportError as e:\n",
        "    print(f\"Missing dependency: {e}\")\n",
        "    print(\"Install with: pip install 'panosam[sam3]'\")\n",
        "    result = None\n",
        "except Exception as e:\n",
        "    print(f\"Error running PanoSAM: {e}\")\n",
        "    print(\"This may be due to missing HuggingFace auth or insufficient GPU memory.\")\n",
        "    print(\"Run: huggingface-cli login\")\n",
        "    result = None"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "6507fc61"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Visualize Segmentation Results\n",
        "\n",
        "PanoSAM returns masks in **spherical coordinates** (yaw/pitch in degrees), so we can visualize them directly on the equirectangular panorama.\n",
        "\n",
        "PanoSAM includes `visualize_sphere_masks()` for overlaying spherical polygon masks onto panoramas."
      ],
      "id": "33bf2bcd"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "if result and len(result.masks) > 0:\n",
        "    # Use PanoSAM's built-in visualization\n",
        "    viz = ps.visualize_sphere_masks(panorama, result.masks, alpha=0.5)\n",
        "\n",
        "    plt.figure(figsize=(20, 10))\n",
        "    plt.imshow(viz)\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(f\"PanoSAM: '{TEXT_PROMPT}' — {len(result.masks)} instance(s) found\", fontsize=14)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"No segmentation results to visualize.\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "e60d153a"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Save Results as JSON\n",
        "\n",
        "PanoSAM can export results in a JSON format compatible with the [PanoSAM Preview Tool](https://yz3440.github.io/panosam/) — an interactive 3D sphere viewer for exploring segmentation results."
      ],
      "id": "83096338"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "if result:\n",
        "    output_path = \"assets/segmentation_result.panosam.json\"\n",
        "    os.makedirs(\"assets\", exist_ok=True)\n",
        "    result.save_json(output_path)\n",
        "    print(f\"Saved results to {output_path}\")\n",
        "    print(f\"Open the PanoSAM preview tool and drag in this JSON + the panorama image:\")\n",
        "    print(f\"  https://yz3440.github.io/panosam/\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "71a1545a"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Try Different Prompts\n",
        "\n",
        "Change `TEXT_PROMPT` in cell 4 above and re-run cells 4–5 to try different objects.\n",
        "\n",
        "Some ideas to try:\n",
        "- `\"car\"` — vehicles on the street\n",
        "- `\"sign\"` — street signs, shop signs\n",
        "- `\"tree\"` — vegetation\n",
        "- `\"person\"` — pedestrians\n",
        "- `\"window\"` — building windows\n",
        "- `\"bicycle\"` — bikes\n",
        "\n",
        "## 8. Multi-Scale Segmentation\n",
        "\n",
        "For objects of varying sizes, you can combine multiple presets. PanoSAM merges and deduplicates masks across all scales automatically."
      ],
      "id": "bf6d4b59"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Optional: Multi-scale segmentation (combines ZOOMED_OUT + WIDEANGLE presets)\n",
        "# Uncomment to run — this processes more views and takes longer\n",
        "\n",
        "# multi_client = ps.PanoSAM(\n",
        "#     engine=engine,\n",
        "#     views=[ps.PerspectivePreset.ZOOMED_OUT, ps.PerspectivePreset.WIDEANGLE],\n",
        "# )\n",
        "# multi_result = multi_client.segment(panorama, prompt=TEXT_PROMPT)\n",
        "# print(f\"Multi-scale: found {len(multi_result.masks)} '{TEXT_PROMPT}' instance(s)\")\n",
        "# multi_result.save_json(\"assets/multi_scale_result.panosam.json\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "134248e0"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
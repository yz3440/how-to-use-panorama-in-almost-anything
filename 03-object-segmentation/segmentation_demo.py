"""
Object Segmentation on 360 Images — Hands-On Demo
===================================================

Detect and segment objects in equirectangular panoramic images using text
prompts, powered by PanoSAM + Meta SAM 3.

Pipeline:
  Equirectangular → Perspective Views → SAM 3 (per view) → Deduplicated Masks
     panorama        (auto-generated)    text prompt         in spherical coords

PanoSAM wraps SAM 3 (Segment Anything Model 3) and handles the full panorama
pipeline — perspective splitting, per-view segmentation, coordinate conversion
back to spherical, and mask deduplication — so you don't have to.

Prerequisites
-------------
  pip install "panosam[full]"
  huggingface-cli login          # accept the SAM 3 model license first

Note: SAM 3 is large. GPU strongly recommended.
"""

import os

from PIL import Image
import matplotlib.pyplot as plt
import panosam as ps

# ---------------------------------------------------------------------------
# 1. Configuration
# ---------------------------------------------------------------------------

SAMPLE_IMAGE = "assets/sample_panorama.jpg"

# Change this to segment different objects.
# Try: "sign", "tree", "window", "person", "building", "bicycle"
TEXT_PROMPT = "car"

# ---------------------------------------------------------------------------
# 2. Load a panorama
#    Place an equirectangular image at assets/sample_panorama.jpg, or
#    this script will download one from Google Street View automatically.
# ---------------------------------------------------------------------------

if not os.path.exists(SAMPLE_IMAGE):
    print("No sample image found. Downloading from Google Street View...")
    from streetlevel import streetview

    pano = streetview.find_panorama(42.3625, -71.0862)  # MIT Media Lab area
    if pano:
        os.makedirs("assets", exist_ok=True)
        streetview.download_panorama(pano, SAMPLE_IMAGE, zoom=4)
        print(f"Downloaded panorama {pano.id}")
    else:
        raise FileNotFoundError(
            "Could not find a panorama. "
            "Please place an image at assets/sample_panorama.jpg"
        )

panorama = Image.open(SAMPLE_IMAGE)
print(f"Panorama size: {panorama.width} x {panorama.height}")

plt.figure(figsize=(16, 8))
plt.imshow(panorama)
plt.axis("off")
plt.title("Equirectangular Panorama")
plt.show()

# ---------------------------------------------------------------------------
# 3. Perspective splitting preview
#    SAM 3 expects standard perspective images. PanoSAM handles the
#    equirectangular-to-perspective projection automatically using
#    configurable presets:
#
#      Preset      FOV    Resolution   Views
#      DEFAULT     45°    2048×2048    16
#      ZOOMED_IN   22.5°  1024×1024    32
#      ZOOMED_OUT  60°    2500×2500    12
#      WIDEANGLE   90°    2500×2500     8
#
#    Custom perspectives: panosam.generate_perspectives()
# ---------------------------------------------------------------------------

pano_image = ps.PanoramaImage(panorama_id="sample", image=panorama)

perspectives = ps.DEFAULT_IMAGE_PERSPECTIVES
print(f"DEFAULT preset: {len(perspectives)} perspectives")
for p in perspectives[:4]:
    print(
        f"  yaw={p.yaw_offset:6.1f}°, pitch={p.pitch_offset:5.1f}°, "
        f"fov={p.horizontal_fov}°, res={p.width}×{p.height}"
    )
print(f"  ... and {len(perspectives) - 4} more")

# Show the first 6 perspective views
sample_perspectives = perspectives[:6]

fig, axes = plt.subplots(2, 3, figsize=(15, 10))
for idx, p in enumerate(sample_perspectives):
    persp_image = pano_image.generate_perspective_image(p)
    pil_view = persp_image.get_perspective_image()

    ax = axes[idx // 3][idx % 3]
    ax.imshow(pil_view)
    ax.set_title(f"Yaw: {p.yaw_offset:.0f}°, Pitch: {p.pitch_offset:.0f}°")
    ax.axis("off")

plt.suptitle("Perspective Views (auto-generated by PanoSAM)", fontsize=14)
plt.tight_layout()
plt.show()

# ---------------------------------------------------------------------------
# 4. Run PanoSAM segmentation
#    The full pipeline in one call:
#      1. Split panorama into perspective views (based on preset)
#      2. Run SAM 3 on each view with the text prompt
#      3. Convert per-view masks to spherical coordinates
#      4. Deduplicate overlapping detections across views
#
#    Prerequisites:
#      - huggingface-cli login (accept the SAM 3 license)
#      - GPU recommended
# ---------------------------------------------------------------------------

print(f"\nSegmenting '{TEXT_PROMPT}' across the full panorama...")

result = None

try:
    from panosam.engines.sam3 import SAM3Engine

    # Initialize the SAM3 engine (downloads model on first run)
    engine = SAM3Engine()

    # WIDEANGLE preset: 8 views, fast. Use DEFAULT (16 views) for more coverage.
    client = ps.PanoSAM(engine=engine, views=ps.PerspectivePreset.WIDEANGLE)

    # Segment — splits, runs SAM3, converts to spherical, and deduplicates
    result = client.segment(panorama, prompt=TEXT_PROMPT)

    print(f"Found {len(result.masks)} '{TEXT_PROMPT}' instance(s)\n")
    for i, mask in enumerate(result.masks):
        print(
            f"  [{i}] score={mask.score:.2f}, "
            f"center=({mask.center_yaw:.1f}°, {mask.center_pitch:.1f}°), "
            f"polygons={len(mask.polygons)}"
        )

except ImportError as e:
    print(f"Missing dependency: {e}")
    print("Install with: pip install 'panosam[sam3]'")
except Exception as e:
    print(f"Error running PanoSAM: {e}")
    print("This may be due to missing HuggingFace auth or insufficient GPU memory.")
    print("Run: huggingface-cli login")

# ---------------------------------------------------------------------------
# 5. Visualize segmentation results
#    PanoSAM returns masks in spherical coordinates (yaw/pitch degrees),
#    so we can overlay them directly on the equirectangular panorama.
# ---------------------------------------------------------------------------

if result and len(result.masks) > 0:
    viz = ps.visualize_sphere_masks(panorama, result.masks, alpha=0.5)

    plt.figure(figsize=(20, 10))
    plt.imshow(viz)
    plt.axis("off")
    plt.title(
        f"PanoSAM: '{TEXT_PROMPT}' — {len(result.masks)} instance(s) found",
        fontsize=14,
    )
    plt.tight_layout()
    plt.show()
else:
    print("No segmentation results to visualize.")

# ---------------------------------------------------------------------------
# 6. Save results as JSON
#    Compatible with the PanoSAM Preview Tool — an interactive 3D sphere
#    viewer for exploring segmentation results.
#    https://yz3440.github.io/panosam/
# ---------------------------------------------------------------------------

if result:
    output_path = "assets/segmentation_result.panosam.json"
    os.makedirs("assets", exist_ok=True)
    result.save_json(output_path)
    print(f"\nSaved results to {output_path}")
    print("Open the PanoSAM preview tool and drag in this JSON + the panorama image:")
    print("  https://yz3440.github.io/panosam/")

# ---------------------------------------------------------------------------
# 7. Multi-scale segmentation (optional)
#    For objects of varying sizes, combine multiple presets. PanoSAM merges
#    and deduplicates masks across all scales automatically.
#
#    Uncomment to run — this processes more views and takes longer.
# ---------------------------------------------------------------------------

# multi_client = ps.PanoSAM(
#     engine=engine,
#     views=[ps.PerspectivePreset.ZOOMED_OUT, ps.PerspectivePreset.WIDEANGLE],
# )
# multi_result = multi_client.segment(panorama, prompt=TEXT_PROMPT)
# print(f"Multi-scale: found {len(multi_result.masks)} '{TEXT_PROMPT}' instance(s)")
# multi_result.save_json("assets/multi_scale_result.panosam.json")
